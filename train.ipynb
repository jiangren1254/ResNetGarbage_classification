{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd7b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入lib\n",
    "# 导入树叶数据集\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=128):\n",
    "    \"\"\"导入数据集\"\"\"\n",
    "    imagenet_mean = [0.485, 0.456, 0.406]\n",
    "    imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    train_trans = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(3./4., 4./3.)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        AutoAugment(policy=AutoAugmentPolicy.IMAGENET), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "    ])\n",
    "\n",
    "    test_trans = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "    ])\n",
    "    root_dir = \"./datasets/train\" \n",
    "    dataset = torchvision.datasets.ImageFolder(root=root_dir)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    train_dataset.dataset = torchvision.datasets.ImageFolder(root=root_dir, transform=train_trans)\n",
    "    test_dataset.dataset = torchvision.datasets.ImageFolder(root=root_dir, transform=test_trans)\n",
    "    num_workers = 4\n",
    "    return (DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=num_workers,pin_memory=True,  prefetch_factor=2,persistent_workers=True),\n",
    "            DataLoader(test_dataset, batch_size=batch_size, shuffle=False,num_workers=num_workers,pin_memory=True,prefetch_factor=2,persistent_workers=True)\n",
    "    )\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "train_iter, test_iter = load_data(batch_size=64)\n",
    "# for i,(X,y) in enumerate(train_iter): # 这里费时间,如何找到合适的num_workers\n",
    "#     # X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "#     X, y = X[:8], y[:8]\n",
    "#     print(\"Batch shape:\", X.shape, \"Labels shape:\", y)\n",
    "#     grid_img = vutils.make_grid(X, nrow=4, normalize=True)  # nrow=4 表示每行 4 张\n",
    "#     plt.figure(figsize=(8, 4))  # 调整图像大小\n",
    "#     plt.imshow(grid_img.permute(1, 2, 0))  # 调整通道顺序 (C, H, W) → (H, W, C)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络\n",
    "finetune_net = torchvision.models.resnet18(weights=True)\n",
    "finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 10)\n",
    "nn.init.xavier_uniform_(finetune_net.fc.weight);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fromKK(net, train_iter, test_iter, num_epochs, lr, device,param_group=True):\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    best_weights = 0\n",
    "    if param_group:\n",
    "        params_1x = [param for name, param in net.named_parameters()\n",
    "             if name not in [\"fc.weight\", \"fc.bias\"]]\n",
    "        optimizer = torch.optim.AdamW([{'params': params_1x},\n",
    "                                   {'params': net.fc.parameters(),\n",
    "                                    'lr': lr * 10}],\n",
    "                                lr=lr, weight_decay=0.001)\n",
    "    else:\n",
    "        optimizer = torch.optim.AdamW(net.parameters(), lr=lr,\n",
    "                                  weight_decay=0.001)\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        train_loss_sum, train_acc_sum,num_samples = 0,0,0\n",
    "        with tqdm(train_iter, desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:  \n",
    "            for X, y in pbar:\n",
    "                optimizer.zero_grad()\n",
    "                X,y = X.to(device),y.to(device)\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat, y)\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "                train_loss_sum += l.item() * X.shape[0]\n",
    "                train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "                num_samples += X.shape[0]\n",
    "                pbar.set_postfix(loss=l.item(), acc=train_acc_sum / num_samples)\n",
    "        train_loss = train_loss_sum / num_samples\n",
    "        train_acc = train_acc_sum / num_samples\n",
    "\n",
    "        # if (epoch+1) ==  num_epochs:\n",
    "        net.eval()  # 评估模式\n",
    "        test_acc_sum, test_samples = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_iter: # 这里也很费时间，连续运行效率极高\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_hat = net(X)\n",
    "                test_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "                test_samples += X.shape[0]\n",
    "        test_acc = test_acc_sum / test_samples\n",
    "        if (test_acc>best_weights):\n",
    "            best_weights = test_acc\n",
    "            torch.save(net.state_dict(), 'test_best.pth')\n",
    "        print(f\"______ | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "lr,num_epochs =5e-5,100\n",
    "net = finetune_net\n",
    "train_fromKK(net,train_iter,test_iter,num_epochs,lr,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe840f0",
   "metadata": {},
   "source": [
    "resNe18\n",
    "test_best_5epoch.pt\n",
    "______ | Train Loss: 0.5319 | Train Acc: 0.8173 | Test Acc: 0.8885\n",
    "验证集精度：0.8885\n",
    "\n",
    "resNe50\n",
    "______ | Train Loss: 0.1763 | Train Acc: 0.9406 | Test Acc: 0.8997\n",
    "验证集精度：0.9064\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('test_best_100epoch_resnet18.pth'))\n",
    "net.eval()  # 评估模式\n",
    "test_acc_sum, test_samples = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X, y in test_iter: # 这里也很费时间，连续运行效率极高\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat = net(X)\n",
    "        test_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "        test_samples += X.shape[0]\n",
    "test_acc = test_acc_sum / test_samples\n",
    "print(f'验证集精度：{test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
