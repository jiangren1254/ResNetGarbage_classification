{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dd7b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入lib\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.transforms import AutoAugment, AutoAugmentPolicy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43cb9fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别名称 → 类别索引 映射：\n",
      "刀片 → 0\n",
      "剩菜剩饭 → 1\n",
      "厨房废品 → 2\n",
      "大骨头 → 3\n",
      "玻璃瓶 → 4\n",
      "瓜果皮壳 → 5\n",
      "肉类 → 6\n",
      "茶叶渣 → 7\n",
      "菜叶菜帮 → 8\n",
      "鱼骨鱼刺 → 9\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import os\n",
    "\n",
    "# 创建 ImageFolder 实例（无需 transform，仅提取类别映射）\n",
    "dataset = datasets.ImageFolder(os.path.join('datasets', 'train'))\n",
    "\n",
    "# 打印类别到索引的映射（中文文件夹名 -> 整数标签）\n",
    "class_to_idx = dataset.class_to_idx\n",
    "print(\"类别名称 → 类别索引 映射：\")\n",
    "for name, idx in class_to_idx.items():\n",
    "    print(f\"{name} → {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4beb0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=128):\n",
    "    \"\"\"导入数据集\"\"\"\n",
    "    imagenet_mean = [0.485, 0.456, 0.406]\n",
    "    imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(3./4., 4./3.)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        AutoAugment(policy=AutoAugmentPolicy.IMAGENET), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
    "    ])\n",
    "    train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(\n",
    "        os.path.join('datasets', folder),\n",
    "        transform=transform_train) for folder in ['train', 'train_valid']]\n",
    "    \n",
    "    valid_ds, test_ds = [torchvision.datasets.ImageFolder(\n",
    "        os.path.join('datasets', folder),\n",
    "        transform=transform_test) for folder in ['valid', 'test']]\n",
    "    num_workers =8\n",
    "    train_iter, train_valid_iter = [torch.utils.data.DataLoader(\n",
    "        dataset, batch_size, shuffle=True, drop_last=True)\n",
    "        for dataset in (train_ds, train_valid_ds)]\n",
    "\n",
    "    valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n",
    "                                            drop_last=True,num_workers=num_workers,\n",
    "                                            pin_memory=True,  prefetch_factor=8,\n",
    "                                            persistent_workers=True)\n",
    "\n",
    "    test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n",
    "                                            drop_last=False,num_workers=num_workers,\n",
    "                                            pin_memory=True,prefetch_factor=8,\n",
    "                                            persistent_workers=True)\n",
    "    return (train_iter, train_valid_iter, valid_iter,test_iter)\n",
    "\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "train_iter, train_valid_iter, valid_iter,test_iter = load_data(batch_size=64)\n",
    "# for i,(X,y) in enumerate(train_iter): # 这里费时间,如何找到合适的num_workers\n",
    "#     # X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "#     X, y = X[:8], y[:8]\n",
    "#     print(\"Batch shape:\", X.shape, \"Labels shape:\", y)\n",
    "#     grid_img = vutils.make_grid(X, nrow=4, normalize=True)  # nrow=4 表示每行 4 张\n",
    "#     plt.figure(figsize=(8, 4))  # 调整图像大小\n",
    "#     plt.imshow(grid_img.permute(1, 2, 0))  # 调整通道顺序 (C, H, W) → (H, W, C)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4066e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda3\\envs\\yolov8_2\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 网络\n",
    "finetune_net = torchvision.models.resnet50(weights=True)\n",
    "finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 10)\n",
    "nn.init.xavier_uniform_(finetune_net.fc.weight);\n",
    "finetune_net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caff7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fromKK(net, train_iter, test_iter, num_epochs, lr, device,param_group=True):\n",
    "    with open('training_metrics.txt', 'w') as f:\n",
    "        f.write(\"Epoch,Train_Loss,Train_Acc,Test_Acc\\n\") \n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    best_weights = 0\n",
    "    if param_group:\n",
    "        params_1x = [param for name, param in net.named_parameters()\n",
    "             if name not in [\"fc.weight\", \"fc.bias\"]]\n",
    "        optimizer = torch.optim.AdamW([{'params': params_1x},\n",
    "                                   {'params': net.fc.parameters(),\n",
    "                                    'lr': lr * 10}],\n",
    "                                lr=lr, weight_decay=0.001)\n",
    "    else:\n",
    "        optimizer = torch.optim.AdamW(net.parameters(), lr=lr,\n",
    "                                  weight_decay=0.001)\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        train_loss_sum, train_acc_sum,num_samples = 0,0,0\n",
    "        with tqdm(train_iter, desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:  \n",
    "            for X, y in pbar:\n",
    "                optimizer.zero_grad()\n",
    "                X,y = X.to(device),y.to(device)\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat, y)\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "                train_loss_sum += l.item() * X.shape[0]\n",
    "                train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "                num_samples += X.shape[0]\n",
    "                pbar.set_postfix(loss=l.item(), acc=train_acc_sum / num_samples)\n",
    "        train_loss = train_loss_sum / num_samples\n",
    "        train_acc = train_acc_sum / num_samples\n",
    "\n",
    "        if test_iter is not None:\n",
    "            net.eval()  # 评估模式\n",
    "            test_acc_sum, test_samples = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for X, y in test_iter: # 这里也很费时间，连续运行效率极高\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    y_hat = net(X)\n",
    "                    test_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "                    test_samples += X.shape[0]\n",
    "            test_acc = test_acc_sum / test_samples\n",
    "            if (test_acc>best_weights):\n",
    "                best_weights = test_acc\n",
    "                torch.save(net.state_dict(), 'test_best.pth')\n",
    "            print(f\"______ | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "            with open('training_metrics.txt', 'a') as f:\n",
    "                f.write(f\"{epoch+1},{train_loss:.4f},{train_acc:.4f},{test_acc:.4f}\\n\")\n",
    "        else:\n",
    "            torch.save(net.state_dict(), 'test_best.pth')\n",
    "            print(f\"______ | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "lr,num_epochs =5e-5,10\n",
    "net = finetune_net\n",
    "train_fromKK(net,train_iter,valid_iter,num_epochs,lr,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe840f0",
   "metadata": {},
   "source": [
    "resNe18\n",
    "test_best_5epoch.pt\n",
    "______ | Train Loss: 0.5319 | Train Acc: 0.8173 | Test Acc: 0.8885\n",
    "验证集精度：0.8885\n",
    "\n",
    "resNe50\n",
    "______ | Train Loss: 0.1763 | Train Acc: 0.9406 | Test Acc: 0.8997\n",
    "验证集精度：0.9064\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d0efb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 257/257 [02:55<00:00,  1.47it/s, acc=0.74, loss=0.635] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______ | Train Loss: 0.7765 | Train Acc: 0.7402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 257/257 [03:04<00:00,  1.40it/s, acc=0.811, loss=0.493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______ | Train Loss: 0.5613 | Train Acc: 0.8110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 257/257 [02:59<00:00,  1.43it/s, acc=0.827, loss=0.596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______ | Train Loss: 0.4968 | Train Acc: 0.8271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 257/257 [03:03<00:00,  1.40it/s, acc=0.847, loss=0.459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______ | Train Loss: 0.4561 | Train Acc: 0.8465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 257/257 [03:02<00:00,  1.41it/s, acc=0.851, loss=0.275]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______ | Train Loss: 0.4359 | Train Acc: 0.8510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 确定超参数后的训练\n",
    "\"\"\"\n",
    "超参数群\n",
    "lr,num_epochs =5e-5,10\n",
    "\"\"\"\n",
    "lr,num_epochs =5e-5,5\n",
    "net = finetune_net\n",
    "train_fromKK(net,train_valid_iter,None,num_epochs,lr,device)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
